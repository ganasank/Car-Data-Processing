{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "import matplotlib\n",
    "import cv2\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import skvideo.io\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stress data\n",
    "#participant C100\n",
    "source='.\\Stress.csv'\n",
    "data=pd.read_csv(source,header=0)\n",
    "l=len(data)\n",
    "for line in range(1,l):\n",
    "    data=data.append({'Unix timestamp': data['Unix timestamp'][line]-1, 'Stress response': data['Stress response'][line-1]}, ignore_index=True)\n",
    "data=data.sort_values(by='Unix timestamp')\n",
    "data.index=pd.to_datetime(data['Unix timestamp'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA_file=pd.read_csv(r'E:\\Stress on the road\\C100\\EDA\\1532049008_A00E6B_C100\\EDA.csv',header=None)\n",
    "EDAstart=EDA_file.values[0]\n",
    "EDAfreq=EDA_file.values[1]\n",
    "EDA=EDA_file.iloc[2:]\n",
    "base=pd.to_datetime(EDAstart,unit='s')\n",
    "arr = np.array([base + timedelta(milliseconds=(i*250)) for i in range(0,len(EDA))])\n",
    "arr=arr.reshape(-1,)\n",
    "EDA.index=arr\n",
    "EDA.columns=['EDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA_HR_file=pd.read_csv(r'E:\\Stress on the road\\C100\\EDA\\1532049008_A00E6B_C100\\HR.csv',header=None)\n",
    "EDAstart_HR=EDA_file.values[0]\n",
    "EDAfreq_HR=EDA_file.values[1]\n",
    "EDA_HR=EDA_HR_file.iloc[2:]\n",
    "base=pd.to_datetime(EDAstart_HR,unit='s')\n",
    "arr = np.array([base + timedelta(seconds=(i)) for i in range(0,len(EDA_HR))])\n",
    "arr=arr.reshape(-1,)\n",
    "EDA_HR.index=arr\n",
    "EDA_HR.columns=['HR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HR and BR data\n",
    "HRsource='E:\\Stress on the road\\C100\\Zephyr\\2018_07_19-18_08_48\\2018_07_19-18_08_48_General.csv'\n",
    "HRdata=pd.read_csv(r'E:\\Stress on the road\\C100\\Zephyr\\2018_07_19-18_08_48\\2018_07_19-18_08_48_General.csv',header=0)\n",
    "HRdata.index=pd.to_datetime(HRdata['Timestamp'],dayfirst=True)\n",
    "#localizing time format, convert it and delocalize it\n",
    "HRdata.index=HRdata.index.tz_localize('US/Pacific').tz_convert('GMT').tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = timedelta(\n",
    "...     days=0,\n",
    "...     seconds=5,\n",
    "...     microseconds=0,\n",
    "...     milliseconds=0,\n",
    "...     minutes=0,\n",
    "...     hours=0,\n",
    "...     weeks=0\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inF=skvideo.io.vread(r'E:\\Stress on the road\\C100\\C100.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vidstart=1532049554.04\n",
    "Vidstart_time=pd.to_datetime('1532049554.04',unit='s')\n",
    "fps=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module cv2.cuda in cv2:\n",
      "\n",
      "NAME\n",
      "    cv2.cuda\n",
      "\n",
      "FUNCTIONS\n",
      "    BroxOpticalFlow_create(...)\n",
      "        BroxOpticalFlow_create([, alpha[, gamma[, scale_factor[, inner_iterations[, outer_iterations[, solver_iterations]]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    CascadeClassifier_create(...)\n",
      "        CascadeClassifier_create(filename) -> retval\n",
      "        .   @brief Loads the classifier from a file. Cascade type is detected automatically by constructor parameter.\n",
      "        .   \n",
      "        .   @param filename Name of the file from which the classifier is loaded. Only the old haar classifier\n",
      "        .   (trained by the haar training application) and NVIDIA's nvbin are supported for HAAR and only new\n",
      "        .   type of OpenCV XML cascade supported for LBP. The working haar models can be found at opencv_folder/data/haarcascades_cuda/\n",
      "    \n",
      "    DensePyrLKOpticalFlow_create(...)\n",
      "        DensePyrLKOpticalFlow_create([, winSize[, maxLevel[, iters[, useInitialFlow]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    DescriptorMatcher_createBFMatcher(...)\n",
      "        DescriptorMatcher_createBFMatcher([, normType]) -> retval\n",
      "        .   @brief Brute-force descriptor matcher.\n",
      "        .   \n",
      "        .   For each descriptor in the first set, this matcher finds the closest descriptor in the second set\n",
      "        .   by trying each one. This descriptor matcher supports masking permissible matches of descriptor\n",
      "        .   sets.\n",
      "        .   \n",
      "        .   @param normType One of NORM_L1, NORM_L2, NORM_HAMMING. L1 and L2 norms are\n",
      "        .   preferable choices for SIFT and SURF descriptors, NORM_HAMMING should be used with ORB, BRISK and\n",
      "        .   BRIEF).\n",
      "    \n",
      "    Event_elapsedTime(...)\n",
      "        Event_elapsedTime(start, end) -> retval\n",
      "        .\n",
      "    \n",
      "    FarnebackOpticalFlow_create(...)\n",
      "        FarnebackOpticalFlow_create([, numLevels[, pyrScale[, fastPyramids[, winSize[, numIters[, polyN[, polySigma[, flags]]]]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    FastFeatureDetector_create(...)\n",
      "        FastFeatureDetector_create([, threshold[, nonmaxSuppression[, type[, max_npoints]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    GpuMat_defaultAllocator(...)\n",
      "        GpuMat_defaultAllocator() -> retval\n",
      "        .\n",
      "    \n",
      "    GpuMat_setDefaultAllocator(...)\n",
      "        GpuMat_setDefaultAllocator(allocator) -> None\n",
      "        .\n",
      "    \n",
      "    HOG_create(...)\n",
      "        HOG_create([, win_size[, block_size[, block_stride[, cell_size[, nbins]]]]]) -> retval\n",
      "        .   @brief Creates the HOG descriptor and detector.\n",
      "        .   \n",
      "        .   @param win_size Detection window size. Align to block size and block stride.\n",
      "        .   @param block_size Block size in pixels. Align to cell size. Only (16,16) is supported for now.\n",
      "        .   @param block_stride Block stride. It must be a multiple of cell size.\n",
      "        .   @param cell_size Cell size. Only (8, 8) is supported for now.\n",
      "        .   @param nbins Number of bins. Only 9 bins per cell are supported for now.\n",
      "    \n",
      "    ORB_create(...)\n",
      "        ORB_create([, nfeatures[, scaleFactor[, nlevels[, edgeThreshold[, firstLevel[, WTA_K[, scoreType[, patchSize[, fastThreshold[, blurForDescriptor]]]]]]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    OpticalFlowDual_TVL1_create(...)\n",
      "        OpticalFlowDual_TVL1_create([, tau[, lambda[, theta[, nscales[, warps[, epsilon[, iterations[, scaleStep[, gamma[, useInitialFlow]]]]]]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    SparsePyrLKOpticalFlow_create(...)\n",
      "        SparsePyrLKOpticalFlow_create([, winSize[, maxLevel[, iters[, useInitialFlow]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    StereoBeliefPropagation_estimateRecommendedParams(...)\n",
      "        StereoBeliefPropagation_estimateRecommendedParams(width, height, ndisp, iters, levels) -> None\n",
      "        .   @brief Uses a heuristic method to compute the recommended parameters ( ndisp, iters and levels ) for the\n",
      "        .   specified image size ( width and height ).\n",
      "    \n",
      "    StereoConstantSpaceBP_estimateRecommendedParams(...)\n",
      "        StereoConstantSpaceBP_estimateRecommendedParams(width, height, ndisp, iters, levels, nr_plane) -> None\n",
      "        .   @brief Uses a heuristic method to compute parameters (ndisp, iters, levelsand nrplane) for the specified\n",
      "        .   image size (widthand height).\n",
      "    \n",
      "    Stream_Null(...)\n",
      "        Stream_Null() -> retval\n",
      "        .   @brief Adds a callback to be called on the host after all currently enqueued items in the stream have\n",
      "        .   completed.\n",
      "        .   \n",
      "        .   @note Callbacks must not make any CUDA API calls. Callbacks must not perform any synchronization\n",
      "        .   that may depend on outstanding device work or other callbacks that are not mandated to run earlier.\n",
      "        .   Callbacks without a mandated order (in independent streams) execute in undefined order and may be\n",
      "        .   serialized.\n",
      "    \n",
      "    TargetArchs_has(...)\n",
      "        TargetArchs_has(major, minor) -> retval\n",
      "        .   @brief There is a set of methods to check whether the module contains intermediate (PTX) or binary CUDA\n",
      "        .   code for the given architecture(s):\n",
      "        .   \n",
      "        .   @param major Major compute capability version.\n",
      "        .   @param minor Minor compute capability version.\n",
      "    \n",
      "    TargetArchs_hasBin(...)\n",
      "        TargetArchs_hasBin(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    TargetArchs_hasEqualOrGreater(...)\n",
      "        TargetArchs_hasEqualOrGreater(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    TargetArchs_hasEqualOrGreaterBin(...)\n",
      "        TargetArchs_hasEqualOrGreaterBin(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    TargetArchs_hasEqualOrGreaterPtx(...)\n",
      "        TargetArchs_hasEqualOrGreaterPtx(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    TargetArchs_hasEqualOrLessPtx(...)\n",
      "        TargetArchs_hasEqualOrLessPtx(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    TargetArchs_hasPtx(...)\n",
      "        TargetArchs_hasPtx(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    abs(...)\n",
      "        abs(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes an absolute value of each matrix element.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa abs\n",
      "    \n",
      "    absSum(...)\n",
      "        absSum(src[, mask]) -> retval\n",
      "        .   @brief Returns the sum of absolute values for matrix elements.\n",
      "        .   \n",
      "        .   @param src Source image of any depth except for CV_64F .\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "    \n",
      "    absdiff(...)\n",
      "        absdiff(src1, src2[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes per-element absolute difference of two matrices (or of a matrix and scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa absdiff\n",
      "    \n",
      "    add(...)\n",
      "        add(src1, src2[, dst[, mask[, dtype[, stream]]]]) -> dst\n",
      "        .   @brief Computes a matrix-matrix or matrix-scalar sum.\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar. Matrix should have the same size and type as src1 .\n",
      "        .   @param dst Destination matrix that has the same size and number of channels as the input array(s).\n",
      "        .   The depth is defined by dtype or src1 depth.\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param dtype Optional depth of the output array.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa add\n",
      "    \n",
      "    addWeighted(...)\n",
      "        addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype[, stream]]]) -> dst\n",
      "        .   @brief Computes the weighted sum of two arrays.\n",
      "        .   \n",
      "        .   @param src1 First source array.\n",
      "        .   @param alpha Weight for the first array elements.\n",
      "        .   @param src2 Second source array of the same size and channel number as src1 .\n",
      "        .   @param beta Weight for the second array elements.\n",
      "        .   @param dst Destination array that has the same size and number of channels as the input arrays.\n",
      "        .   @param gamma Scalar added to each sum.\n",
      "        .   @param dtype Optional depth of the destination array. When both input arrays have the same depth,\n",
      "        .   dtype can be set to -1, which will be equivalent to src1.depth().\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function addWeighted calculates the weighted sum of two arrays as follows:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{saturate} ( \\texttt{src1} (I)* \\texttt{alpha} +  \\texttt{src2} (I)* \\texttt{beta} +  \\texttt{gamma} )\\f]\n",
      "        .   \n",
      "        .   where I is a multi-dimensional index of array elements. In case of multi-channel arrays, each\n",
      "        .   channel is processed independently.\n",
      "        .   \n",
      "        .   @sa addWeighted\n",
      "    \n",
      "    alphaComp(...)\n",
      "        alphaComp(img1, img2, alpha_op[, dst[, stream]]) -> dst\n",
      "        .   @brief Composites two images using alpha opacity values contained in each image.\n",
      "        .   \n",
      "        .   @param img1 First image. Supports CV_8UC4 , CV_16UC4 , CV_32SC4 and CV_32FC4 types.\n",
      "        .   @param img2 Second image. Must have the same size and the same type as img1 .\n",
      "        .   @param dst Destination image.\n",
      "        .   @param alpha_op Flag specifying the alpha-blending operation:\n",
      "        .   -   **ALPHA_OVER**\n",
      "        .   -   **ALPHA_IN**\n",
      "        .   -   **ALPHA_OUT**\n",
      "        .   -   **ALPHA_ATOP**\n",
      "        .   -   **ALPHA_XOR**\n",
      "        .   -   **ALPHA_PLUS**\n",
      "        .   -   **ALPHA_OVER_PREMUL**\n",
      "        .   -   **ALPHA_IN_PREMUL**\n",
      "        .   -   **ALPHA_OUT_PREMUL**\n",
      "        .   -   **ALPHA_ATOP_PREMUL**\n",
      "        .   -   **ALPHA_XOR_PREMUL**\n",
      "        .   -   **ALPHA_PLUS_PREMUL**\n",
      "        .   -   **ALPHA_PREMUL**\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   An example demonstrating the use of alphaComp can be found at\n",
      "        .   opencv_source_code/samples/gpu/alpha_comp.cpp\n",
      "    \n",
      "    bilateralFilter(...)\n",
      "        bilateralFilter(src, kernel_size, sigma_color, sigma_spatial[, dst[, borderMode[, stream]]]) -> dst\n",
      "        .   @brief Performs bilateral filtering of passed image\n",
      "        .   \n",
      "        .   @param src Source image. Supports only (channels != 2 && depth() != CV_8S && depth() != CV_32S\n",
      "        .   && depth() != CV_64F).\n",
      "        .   @param dst Destination imagwe.\n",
      "        .   @param kernel_size Kernel window size.\n",
      "        .   @param sigma_color Filter sigma in the color space.\n",
      "        .   @param sigma_spatial Filter sigma in the coordinate space.\n",
      "        .   @param borderMode Border type. See borderInterpolate for details. BORDER_REFLECT101 ,\n",
      "        .   BORDER_REPLICATE , BORDER_CONSTANT , BORDER_REFLECT and BORDER_WRAP are supported for now.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa bilateralFilter\n",
      "    \n",
      "    bitwise_and(...)\n",
      "        bitwise_and(src1, src2[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element bitwise conjunction of two matrices (or of matrix and scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    bitwise_not(...)\n",
      "        bitwise_not(src[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element bitwise inversion.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    bitwise_or(...)\n",
      "        bitwise_or(src1, src2[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element bitwise disjunction of two matrices (or of matrix and scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    bitwise_xor(...)\n",
      "        bitwise_xor(src1, src2[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element bitwise exclusive or operation of two matrices (or of matrix and scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    blendLinear(...)\n",
      "        blendLinear(img1, img2, weights1, weights2[, result[, stream]]) -> result\n",
      "        .   @brief Performs linear blending of two images.\n",
      "        .   \n",
      "        .   @param img1 First image. Supports only CV_8U and CV_32F depth.\n",
      "        .   @param img2 Second image. Must have the same size and the same type as img1 .\n",
      "        .   @param weights1 Weights for first image. Must have tha same size as img1 . Supports only CV_32F\n",
      "        .   type.\n",
      "        .   @param weights2 Weights for second image. Must have tha same size as img2 . Supports only CV_32F\n",
      "        .   type.\n",
      "        .   @param result Destination image.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    buildWarpAffineMaps(...)\n",
      "        buildWarpAffineMaps(M, inverse, dsize[, xmap[, ymap[, stream]]]) -> xmap, ymap\n",
      "        .   @brief Builds transformation maps for affine transformation.\n",
      "        .   \n",
      "        .   @param M *2x3* transformation matrix.\n",
      "        .   @param inverse Flag specifying that M is an inverse transformation ( dst=\\>src ).\n",
      "        .   @param dsize Size of the destination image.\n",
      "        .   @param xmap X values with CV_32FC1 type.\n",
      "        .   @param ymap Y values with CV_32FC1 type.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa cuda::warpAffine , cuda::remap\n",
      "    \n",
      "    buildWarpPerspectiveMaps(...)\n",
      "        buildWarpPerspectiveMaps(M, inverse, dsize[, xmap[, ymap[, stream]]]) -> xmap, ymap\n",
      "        .   @brief Builds transformation maps for perspective transformation.\n",
      "        .   \n",
      "        .   @param M *3x3* transformation matrix.\n",
      "        .   @param inverse Flag specifying that M is an inverse transformation ( dst=\\>src ).\n",
      "        .   @param dsize Size of the destination image.\n",
      "        .   @param xmap X values with CV_32FC1 type.\n",
      "        .   @param ymap Y values with CV_32FC1 type.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa cuda::warpPerspective , cuda::remap\n",
      "    \n",
      "    calcAbsSum(...)\n",
      "        calcAbsSum(src[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    calcHist(...)\n",
      "        calcHist(src[, hist[, stream]]) -> hist\n",
      "        .   @brief Calculates histogram for one channel 8-bit image.\n",
      "        .   \n",
      "        .   @param src Source image with CV_8UC1 type.\n",
      "        .   @param hist Destination histogram with one row, 256 columns, and the CV_32SC1 type.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        \n",
      "        \n",
      "        \n",
      "        calcHist(src, mask[, hist[, stream]]) -> hist\n",
      "        .   @brief Calculates histogram for one channel 8-bit image confined in given mask.\n",
      "        .   \n",
      "        .   @param src Source image with CV_8UC1 type.\n",
      "        .   @param hist Destination histogram with one row, 256 columns, and the CV_32SC1 type.\n",
      "        .   @param mask A mask image same size as src and of type CV_8UC1.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    calcNorm(...)\n",
      "        calcNorm(src, normType[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    calcNormDiff(...)\n",
      "        calcNormDiff(src1, src2[, dst[, normType[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    calcSqrSum(...)\n",
      "        calcSqrSum(src[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    calcSum(...)\n",
      "        calcSum(src[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    cartToPolar(...)\n",
      "        cartToPolar(x, y[, magnitude[, angle[, angleInDegrees[, stream]]]]) -> magnitude, angle\n",
      "        .   @brief Converts Cartesian coordinates into polar.\n",
      "        .   \n",
      "        .   @param x Source matrix containing real components ( CV_32FC1 ).\n",
      "        .   @param y Source matrix containing imaginary components ( CV_32FC1 ).\n",
      "        .   @param magnitude Destination matrix of float magnitudes ( CV_32FC1 ).\n",
      "        .   @param angle Destination matrix of angles ( CV_32FC1 ).\n",
      "        .   @param angleInDegrees Flag for angles that must be evaluated in degrees.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa cartToPolar\n",
      "    \n",
      "    compare(...)\n",
      "        compare(src1, src2, cmpop[, dst[, stream]]) -> dst\n",
      "        .   @brief Compares elements of two matrices (or of a matrix and scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size as the input array(s) and type CV_8U.\n",
      "        .   @param cmpop Flag specifying the relation between the elements to be checked:\n",
      "        .   -   **CMP_EQ:** a(.) == b(.)\n",
      "        .   -   **CMP_GT:** a(.) \\> b(.)\n",
      "        .   -   **CMP_GE:** a(.) \\>= b(.)\n",
      "        .   -   **CMP_LT:** a(.) \\< b(.)\n",
      "        .   -   **CMP_LE:** a(.) \\<= b(.)\n",
      "        .   -   **CMP_NE:** a(.) != b(.)\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa compare\n",
      "    \n",
      "    copyMakeBorder(...)\n",
      "        copyMakeBorder(src, top, bottom, left, right, borderType[, dst[, value[, stream]]]) -> dst\n",
      "        .   @brief Forms a border around an image.\n",
      "        .   \n",
      "        .   @param src Source image. CV_8UC1 , CV_8UC4 , CV_32SC1 , and CV_32FC1 types are supported.\n",
      "        .   @param dst Destination image with the same type as src. The size is\n",
      "        .   Size(src.cols+left+right, src.rows+top+bottom) .\n",
      "        .   @param top\n",
      "        .   @param bottom\n",
      "        .   @param left\n",
      "        .   @param right Number of pixels in each direction from the source image rectangle to extrapolate.\n",
      "        .   For example: top=1, bottom=1, left=1, right=1 mean that 1 pixel-wide border needs to be built.\n",
      "        .   @param borderType Border type. See borderInterpolate for details. BORDER_REFLECT101 ,\n",
      "        .   BORDER_REPLICATE , BORDER_CONSTANT , BORDER_REFLECT and BORDER_WRAP are supported for now.\n",
      "        .   @param value Border value.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    countNonZero(...)\n",
      "        countNonZero(src) -> retval\n",
      "        .   @brief Counts non-zero matrix elements.\n",
      "        .   \n",
      "        .   @param src Single-channel source image.\n",
      "        .   \n",
      "        .   The function does not work with CV_64F images on GPUs with the compute capability \\< 1.3.\n",
      "        .   \n",
      "        .   @sa countNonZero\n",
      "        \n",
      "        \n",
      "        \n",
      "        countNonZero(src[, dst[, stream]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    createBackgroundSubtractorMOG(...)\n",
      "        createBackgroundSubtractorMOG([, history[, nmixtures[, backgroundRatio[, noiseSigma]]]]) -> retval\n",
      "        .   @brief Creates mixture-of-gaussian background subtractor\n",
      "        .   \n",
      "        .   @param history Length of the history.\n",
      "        .   @param nmixtures Number of Gaussian mixtures.\n",
      "        .   @param backgroundRatio Background ratio.\n",
      "        .   @param noiseSigma Noise strength (standard deviation of the brightness or each color channel). 0\n",
      "        .   means some automatic value.\n",
      "    \n",
      "    createBackgroundSubtractorMOG2(...)\n",
      "        createBackgroundSubtractorMOG2([, history[, varThreshold[, detectShadows]]]) -> retval\n",
      "        .   @brief Creates MOG2 Background Subtractor\n",
      "        .   \n",
      "        .   @param history Length of the history.\n",
      "        .   @param varThreshold Threshold on the squared Mahalanobis distance between the pixel and the model\n",
      "        .   to decide whether a pixel is well described by the background model. This parameter does not\n",
      "        .   affect the background update.\n",
      "        .   @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the\n",
      "        .   speed a bit, so if you do not need this feature, set the parameter to false.\n",
      "    \n",
      "    createBoxFilter(...)\n",
      "        createBoxFilter(srcType, dstType, ksize[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates a normalized 2D box filter.\n",
      "        .   \n",
      "        .   @param srcType Input image type. Only CV_8UC1, CV_8UC4 and CV_32FC1 are supported for now.\n",
      "        .   @param dstType Output image type. Only the same type as src is supported for now.\n",
      "        .   @param ksize Kernel size.\n",
      "        .   @param anchor Anchor point. The default value Point(-1, -1) means that the anchor is at the kernel\n",
      "        .   center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "        .   \n",
      "        .   @sa boxFilter\n",
      "    \n",
      "    createBoxMaxFilter(...)\n",
      "        createBoxMaxFilter(srcType, ksize[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates the maximum filter.\n",
      "        .   \n",
      "        .   @param srcType Input/output image type. Only CV_8UC1 and CV_8UC4 are supported.\n",
      "        .   @param ksize Kernel size.\n",
      "        .   @param anchor Anchor point. The default value (-1) means that the anchor is at the kernel center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "    \n",
      "    createBoxMinFilter(...)\n",
      "        createBoxMinFilter(srcType, ksize[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates the minimum filter.\n",
      "        .   \n",
      "        .   @param srcType Input/output image type. Only CV_8UC1 and CV_8UC4 are supported.\n",
      "        .   @param ksize Kernel size.\n",
      "        .   @param anchor Anchor point. The default value (-1) means that the anchor is at the kernel center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "    \n",
      "    createCLAHE(...)\n",
      "        createCLAHE([, clipLimit[, tileGridSize]]) -> retval\n",
      "        .   @brief Creates implementation for cuda::CLAHE .\n",
      "        .   \n",
      "        .   @param clipLimit Threshold for contrast limiting.\n",
      "        .   @param tileGridSize Size of grid for histogram equalization. Input image will be divided into\n",
      "        .   equally sized rectangular tiles. tileGridSize defines the number of tiles in row and column.\n",
      "    \n",
      "    createCannyEdgeDetector(...)\n",
      "        createCannyEdgeDetector(low_thresh, high_thresh[, apperture_size[, L2gradient]]) -> retval\n",
      "        .   @brief Creates implementation for cuda::CannyEdgeDetector .\n",
      "        .   \n",
      "        .   @param low_thresh First threshold for the hysteresis procedure.\n",
      "        .   @param high_thresh Second threshold for the hysteresis procedure.\n",
      "        .   @param apperture_size Aperture size for the Sobel operator.\n",
      "        .   @param L2gradient Flag indicating whether a more accurate \\f$L_2\\f$ norm\n",
      "        .   \\f$=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\f$ should be used to compute the image gradient magnitude (\n",
      "        .   L2gradient=true ), or a faster default \\f$L_1\\f$ norm \\f$=|dI/dx|+|dI/dy|\\f$ is enough ( L2gradient=false\n",
      "        .   ).\n",
      "    \n",
      "    createColumnSumFilter(...)\n",
      "        createColumnSumFilter(srcType, dstType, ksize[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates a vertical 1D box filter.\n",
      "        .   \n",
      "        .   @param srcType Input image type. Only CV_8UC1 type is supported for now.\n",
      "        .   @param dstType Output image type. Only CV_32FC1 type is supported for now.\n",
      "        .   @param ksize Kernel size.\n",
      "        .   @param anchor Anchor point. The default value (-1) means that the anchor is at the kernel center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "    \n",
      "    createContinuous(...)\n",
      "        createContinuous(rows, cols, type[, arr]) -> arr\n",
      "        .   @brief Creates a continuous matrix.\n",
      "        .   \n",
      "        .   @param rows Row count.\n",
      "        .   @param cols Column count.\n",
      "        .   @param type Type of the matrix.\n",
      "        .   @param arr Destination matrix. This parameter changes only if it has a proper type and area (\n",
      "        .   \\f$\\texttt{rows} \\times \\texttt{cols}\\f$ ).\n",
      "        .   \n",
      "        .   Matrix is called continuous if its elements are stored continuously, that is, without gaps at the\n",
      "        .   end of each row.\n",
      "    \n",
      "    createConvolution(...)\n",
      "        createConvolution([, user_block_size]) -> retval\n",
      "        .   @brief Creates implementation for cuda::Convolution .\n",
      "        .   \n",
      "        .   @param user_block_size Block size. If you leave default value Size(0,0) then automatic\n",
      "        .   estimation of block size will be used (which is optimized for speed). By varying user_block_size\n",
      "        .   you can reduce memory requirements at the cost of speed.\n",
      "    \n",
      "    createDFT(...)\n",
      "        createDFT(dft_size, flags) -> retval\n",
      "        .   @brief Creates implementation for cuda::DFT.\n",
      "        .   \n",
      "        .   @param dft_size The image size.\n",
      "        .   @param flags Optional flags:\n",
      "        .   -   **DFT_ROWS** transforms each individual row of the source matrix.\n",
      "        .   -   **DFT_SCALE** scales the result: divide it by the number of elements in the transform\n",
      "        .   (obtained from dft_size ).\n",
      "        .   -   **DFT_INVERSE** inverts DFT. Use for complex-complex cases (real-complex and complex-real\n",
      "        .   cases are always forward and inverse, respectively).\n",
      "        .   -   **DFT_COMPLEX_INPUT** Specifies that inputs will be complex with 2 channels.\n",
      "        .   -   **DFT_REAL_OUTPUT** specifies the output as real. The source matrix is the result of\n",
      "        .   real-complex transform, so the destination matrix must be real.\n",
      "    \n",
      "    createDerivFilter(...)\n",
      "        createDerivFilter(srcType, dstType, dx, dy, ksize[, normalize[, scale[, rowBorderMode[, columnBorderMode]]]]) -> retval\n",
      "        .   @brief Creates a generalized Deriv operator.\n",
      "        .   \n",
      "        .   @param srcType Source image type.\n",
      "        .   @param dstType Destination array type.\n",
      "        .   @param dx Derivative order in respect of x.\n",
      "        .   @param dy Derivative order in respect of y.\n",
      "        .   @param ksize Aperture size. See getDerivKernels for details.\n",
      "        .   @param normalize Flag indicating whether to normalize (scale down) the filter coefficients or not.\n",
      "        .   See getDerivKernels for details.\n",
      "        .   @param scale Optional scale factor for the computed derivative values. By default, no scaling is\n",
      "        .   applied. For details, see getDerivKernels .\n",
      "        .   @param rowBorderMode Pixel extrapolation method in the vertical direction. For details, see\n",
      "        .   borderInterpolate.\n",
      "        .   @param columnBorderMode Pixel extrapolation method in the horizontal direction.\n",
      "    \n",
      "    createDisparityBilateralFilter(...)\n",
      "        createDisparityBilateralFilter([, ndisp[, radius[, iters]]]) -> retval\n",
      "        .   @brief Creates DisparityBilateralFilter object.\n",
      "        .   \n",
      "        .   @param ndisp Number of disparities.\n",
      "        .   @param radius Filter radius.\n",
      "        .   @param iters Number of iterations.\n",
      "    \n",
      "    createGaussianFilter(...)\n",
      "        createGaussianFilter(srcType, dstType, ksize, sigma1[, sigma2[, rowBorderMode[, columnBorderMode]]]) -> retval\n",
      "        .   @brief Creates a Gaussian filter.\n",
      "        .   \n",
      "        .   @param srcType Source image type.\n",
      "        .   @param dstType Destination array type.\n",
      "        .   @param ksize Aperture size. See getGaussianKernel for details.\n",
      "        .   @param sigma1 Gaussian sigma in the horizontal direction. See getGaussianKernel for details.\n",
      "        .   @param sigma2 Gaussian sigma in the vertical direction. If 0, then\n",
      "        .   \\f$\\texttt{sigma2}\\leftarrow\\texttt{sigma1}\\f$ .\n",
      "        .   @param rowBorderMode Pixel extrapolation method in the vertical direction. For details, see\n",
      "        .   borderInterpolate.\n",
      "        .   @param columnBorderMode Pixel extrapolation method in the horizontal direction.\n",
      "        .   \n",
      "        .   @sa GaussianBlur\n",
      "    \n",
      "    createGeneralizedHoughBallard(...)\n",
      "        createGeneralizedHoughBallard() -> retval\n",
      "        .   @brief Creates implementation for generalized hough transform from @cite Ballard1981 .\n",
      "    \n",
      "    createGeneralizedHoughGuil(...)\n",
      "        createGeneralizedHoughGuil() -> retval\n",
      "        .   @brief Creates implementation for generalized hough transform from @cite Guil1999 .\n",
      "    \n",
      "    createGoodFeaturesToTrackDetector(...)\n",
      "        createGoodFeaturesToTrackDetector(srcType[, maxCorners[, qualityLevel[, minDistance[, blockSize[, useHarrisDetector[, harrisK]]]]]]) -> retval\n",
      "        .   @brief Creates implementation for cuda::CornersDetector .\n",
      "        .   \n",
      "        .   @param srcType Input source type. Only CV_8UC1 and CV_32FC1 are supported for now.\n",
      "        .   @param maxCorners Maximum number of corners to return. If there are more corners than are found,\n",
      "        .   the strongest of them is returned.\n",
      "        .   @param qualityLevel Parameter characterizing the minimal accepted quality of image corners. The\n",
      "        .   parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue\n",
      "        .   (see cornerMinEigenVal ) or the Harris function response (see cornerHarris ). The corners with the\n",
      "        .   quality measure less than the product are rejected. For example, if the best corner has the\n",
      "        .   quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure\n",
      "        .   less than 15 are rejected.\n",
      "        .   @param minDistance Minimum possible Euclidean distance between the returned corners.\n",
      "        .   @param blockSize Size of an average block for computing a derivative covariation matrix over each\n",
      "        .   pixel neighborhood. See cornerEigenValsAndVecs .\n",
      "        .   @param useHarrisDetector Parameter indicating whether to use a Harris detector (see cornerHarris)\n",
      "        .   or cornerMinEigenVal.\n",
      "        .   @param harrisK Free parameter of the Harris detector.\n",
      "    \n",
      "    createHarrisCorner(...)\n",
      "        createHarrisCorner(srcType, blockSize, ksize, k[, borderType]) -> retval\n",
      "        .   @brief Creates implementation for Harris cornerness criteria.\n",
      "        .   \n",
      "        .   @param srcType Input source type. Only CV_8UC1 and CV_32FC1 are supported for now.\n",
      "        .   @param blockSize Neighborhood size.\n",
      "        .   @param ksize Aperture parameter for the Sobel operator.\n",
      "        .   @param k Harris detector free parameter.\n",
      "        .   @param borderType Pixel extrapolation method. Only BORDER_REFLECT101 and BORDER_REPLICATE are\n",
      "        .   supported for now.\n",
      "        .   \n",
      "        .   @sa cornerHarris\n",
      "    \n",
      "    createHoughCirclesDetector(...)\n",
      "        createHoughCirclesDetector(dp, minDist, cannyThreshold, votesThreshold, minRadius, maxRadius[, maxCircles]) -> retval\n",
      "        .   @brief Creates implementation for cuda::HoughCirclesDetector .\n",
      "        .   \n",
      "        .   @param dp Inverse ratio of the accumulator resolution to the image resolution. For example, if\n",
      "        .   dp=1 , the accumulator has the same resolution as the input image. If dp=2 , the accumulator has\n",
      "        .   half as big width and height.\n",
      "        .   @param minDist Minimum distance between the centers of the detected circles. If the parameter is\n",
      "        .   too small, multiple neighbor circles may be falsely detected in addition to a true one. If it is\n",
      "        .   too large, some circles may be missed.\n",
      "        .   @param cannyThreshold The higher threshold of the two passed to Canny edge detector (the lower one\n",
      "        .   is twice smaller).\n",
      "        .   @param votesThreshold The accumulator threshold for the circle centers at the detection stage. The\n",
      "        .   smaller it is, the more false circles may be detected.\n",
      "        .   @param minRadius Minimum circle radius.\n",
      "        .   @param maxRadius Maximum circle radius.\n",
      "        .   @param maxCircles Maximum number of output circles.\n",
      "    \n",
      "    createHoughLinesDetector(...)\n",
      "        createHoughLinesDetector(rho, theta, threshold[, doSort[, maxLines]]) -> retval\n",
      "        .   @brief Creates implementation for cuda::HoughLinesDetector .\n",
      "        .   \n",
      "        .   @param rho Distance resolution of the accumulator in pixels.\n",
      "        .   @param theta Angle resolution of the accumulator in radians.\n",
      "        .   @param threshold Accumulator threshold parameter. Only those lines are returned that get enough\n",
      "        .   votes ( \\f$>\\texttt{threshold}\\f$ ).\n",
      "        .   @param doSort Performs lines sort by votes.\n",
      "        .   @param maxLines Maximum number of output lines.\n",
      "    \n",
      "    createHoughSegmentDetector(...)\n",
      "        createHoughSegmentDetector(rho, theta, minLineLength, maxLineGap[, maxLines]) -> retval\n",
      "        .   @brief Creates implementation for cuda::HoughSegmentDetector .\n",
      "        .   \n",
      "        .   @param rho Distance resolution of the accumulator in pixels.\n",
      "        .   @param theta Angle resolution of the accumulator in radians.\n",
      "        .   @param minLineLength Minimum line length. Line segments shorter than that are rejected.\n",
      "        .   @param maxLineGap Maximum allowed gap between points on the same line to link them.\n",
      "        .   @param maxLines Maximum number of output lines.\n",
      "    \n",
      "    createLaplacianFilter(...)\n",
      "        createLaplacianFilter(srcType, dstType[, ksize[, scale[, borderMode[, borderVal]]]]) -> retval\n",
      "        .   @brief Creates a Laplacian operator.\n",
      "        .   \n",
      "        .   @param srcType Input image type. Supports CV_8U , CV_16U and CV_32F one and four channel image.\n",
      "        .   @param dstType Output image type. Only the same type as src is supported for now.\n",
      "        .   @param ksize Aperture size used to compute the second-derivative filters (see getDerivKernels). It\n",
      "        .   must be positive and odd. Only ksize = 1 and ksize = 3 are supported.\n",
      "        .   @param scale Optional scale factor for the computed Laplacian values. By default, no scaling is\n",
      "        .   applied (see getDerivKernels ).\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "        .   \n",
      "        .   @sa Laplacian\n",
      "    \n",
      "    createLinearFilter(...)\n",
      "        createLinearFilter(srcType, dstType, kernel[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates a non-separable linear 2D filter.\n",
      "        .   \n",
      "        .   @param srcType Input image type. Supports CV_8U , CV_16U and CV_32F one and four channel image.\n",
      "        .   @param dstType Output image type. Only the same type as src is supported for now.\n",
      "        .   @param kernel 2D array of filter coefficients.\n",
      "        .   @param anchor Anchor point. The default value Point(-1, -1) means that the anchor is at the kernel\n",
      "        .   center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "        .   \n",
      "        .   @sa filter2D\n",
      "    \n",
      "    createLookUpTable(...)\n",
      "        createLookUpTable(lut) -> retval\n",
      "        .   @brief Creates implementation for cuda::LookUpTable .\n",
      "        .   \n",
      "        .   @param lut Look-up table of 256 elements. It is a continuous CV_8U matrix.\n",
      "    \n",
      "    createMedianFilter(...)\n",
      "        createMedianFilter(srcType, windowSize[, partition]) -> retval\n",
      "        .   @brief Performs median filtering for each point of the source image.\n",
      "        .   \n",
      "        .   @param srcType type of of source image. Only CV_8UC1 images are supported for now.\n",
      "        .   @param windowSize Size of the kernerl used for the filtering. Uses a (windowSize x windowSize) filter.\n",
      "        .   @param partition Specifies the parallel granularity of the workload. This parameter should be used GPU experts when optimizing performance.\n",
      "        .   \n",
      "        .   Outputs an image that has been filtered using median-filtering formulation.\n",
      "    \n",
      "    createMinEigenValCorner(...)\n",
      "        createMinEigenValCorner(srcType, blockSize, ksize[, borderType]) -> retval\n",
      "        .   @brief Creates implementation for the minimum eigen value of a 2x2 derivative covariation matrix (the\n",
      "        .   cornerness criteria).\n",
      "        .   \n",
      "        .   @param srcType Input source type. Only CV_8UC1 and CV_32FC1 are supported for now.\n",
      "        .   @param blockSize Neighborhood size.\n",
      "        .   @param ksize Aperture parameter for the Sobel operator.\n",
      "        .   @param borderType Pixel extrapolation method. Only BORDER_REFLECT101 and BORDER_REPLICATE are\n",
      "        .   supported for now.\n",
      "        .   \n",
      "        .   @sa cornerMinEigenVal\n",
      "    \n",
      "    createMorphologyFilter(...)\n",
      "        createMorphologyFilter(op, srcType, kernel[, anchor[, iterations]]) -> retval\n",
      "        .   @brief Creates a 2D morphological filter.\n",
      "        .   \n",
      "        .   @param op Type of morphological operation. The following types are possible:\n",
      "        .   -   **MORPH_ERODE** erode\n",
      "        .   -   **MORPH_DILATE** dilate\n",
      "        .   -   **MORPH_OPEN** opening\n",
      "        .   -   **MORPH_CLOSE** closing\n",
      "        .   -   **MORPH_GRADIENT** morphological gradient\n",
      "        .   -   **MORPH_TOPHAT** \"top hat\"\n",
      "        .   -   **MORPH_BLACKHAT** \"black hat\"\n",
      "        .   @param srcType Input/output image type. Only CV_8UC1, CV_8UC4, CV_32FC1 and CV_32FC4 are supported.\n",
      "        .   @param kernel 2D 8-bit structuring element for the morphological operation.\n",
      "        .   @param anchor Anchor position within the structuring element. Negative values mean that the anchor\n",
      "        .   is at the center.\n",
      "        .   @param iterations Number of times erosion and dilation to be applied.\n",
      "        .   \n",
      "        .   @sa morphologyEx\n",
      "    \n",
      "    createRowSumFilter(...)\n",
      "        createRowSumFilter(srcType, dstType, ksize[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates a horizontal 1D box filter.\n",
      "        .   \n",
      "        .   @param srcType Input image type. Only CV_8UC1 type is supported for now.\n",
      "        .   @param dstType Output image type. Only CV_32FC1 type is supported for now.\n",
      "        .   @param ksize Kernel size.\n",
      "        .   @param anchor Anchor point. The default value (-1) means that the anchor is at the kernel center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "    \n",
      "    createScharrFilter(...)\n",
      "        createScharrFilter(srcType, dstType, dx, dy[, scale[, rowBorderMode[, columnBorderMode]]]) -> retval\n",
      "        .   @brief Creates a vertical or horizontal Scharr operator.\n",
      "        .   \n",
      "        .   @param srcType Source image type.\n",
      "        .   @param dstType Destination array type.\n",
      "        .   @param dx Order of the derivative x.\n",
      "        .   @param dy Order of the derivative y.\n",
      "        .   @param scale Optional scale factor for the computed derivative values. By default, no scaling is\n",
      "        .   applied. See getDerivKernels for details.\n",
      "        .   @param rowBorderMode Pixel extrapolation method in the vertical direction. For details, see\n",
      "        .   borderInterpolate.\n",
      "        .   @param columnBorderMode Pixel extrapolation method in the horizontal direction.\n",
      "        .   \n",
      "        .   @sa Scharr\n",
      "    \n",
      "    createSeparableLinearFilter(...)\n",
      "        createSeparableLinearFilter(srcType, dstType, rowKernel, columnKernel[, anchor[, rowBorderMode[, columnBorderMode]]]) -> retval\n",
      "        .   @brief Creates a separable linear filter.\n",
      "        .   \n",
      "        .   @param srcType Source array type.\n",
      "        .   @param dstType Destination array type.\n",
      "        .   @param rowKernel Horizontal filter coefficients. Support kernels with size \\<= 32 .\n",
      "        .   @param columnKernel Vertical filter coefficients. Support kernels with size \\<= 32 .\n",
      "        .   @param anchor Anchor position within the kernel. Negative values mean that anchor is positioned at\n",
      "        .   the aperture center.\n",
      "        .   @param rowBorderMode Pixel extrapolation method in the vertical direction For details, see\n",
      "        .   borderInterpolate.\n",
      "        .   @param columnBorderMode Pixel extrapolation method in the horizontal direction.\n",
      "        .   \n",
      "        .   @sa sepFilter2D\n",
      "    \n",
      "    createSobelFilter(...)\n",
      "        createSobelFilter(srcType, dstType, dx, dy[, ksize[, scale[, rowBorderMode[, columnBorderMode]]]]) -> retval\n",
      "        .   @brief Creates a Sobel operator.\n",
      "        .   \n",
      "        .   @param srcType Source image type.\n",
      "        .   @param dstType Destination array type.\n",
      "        .   @param dx Derivative order in respect of x.\n",
      "        .   @param dy Derivative order in respect of y.\n",
      "        .   @param ksize Size of the extended Sobel kernel. Possible values are 1, 3, 5 or 7.\n",
      "        .   @param scale Optional scale factor for the computed derivative values. By default, no scaling is\n",
      "        .   applied. For details, see getDerivKernels .\n",
      "        .   @param rowBorderMode Pixel extrapolation method in the vertical direction. For details, see\n",
      "        .   borderInterpolate.\n",
      "        .   @param columnBorderMode Pixel extrapolation method in the horizontal direction.\n",
      "        .   \n",
      "        .   @sa Sobel\n",
      "    \n",
      "    createStereoBM(...)\n",
      "        createStereoBM([, numDisparities[, blockSize]]) -> retval\n",
      "        .   @brief Creates StereoBM object.\n",
      "        .   \n",
      "        .   @param numDisparities the disparity search range. For each pixel algorithm will find the best\n",
      "        .   disparity from 0 (default minimum disparity) to numDisparities. The search range can then be\n",
      "        .   shifted by changing the minimum disparity.\n",
      "        .   @param blockSize the linear size of the blocks compared by the algorithm. The size should be odd\n",
      "        .   (as the block is centered at the current pixel). Larger block size implies smoother, though less\n",
      "        .   accurate disparity map. Smaller block size gives more detailed disparity map, but there is higher\n",
      "        .   chance for algorithm to find a wrong correspondence.\n",
      "    \n",
      "    createStereoBeliefPropagation(...)\n",
      "        createStereoBeliefPropagation([, ndisp[, iters[, levels[, msg_type]]]]) -> retval\n",
      "        .   @brief Creates StereoBeliefPropagation object.\n",
      "        .   \n",
      "        .   @param ndisp Number of disparities.\n",
      "        .   @param iters Number of BP iterations on each level.\n",
      "        .   @param levels Number of levels.\n",
      "        .   @param msg_type Type for messages. CV_16SC1 and CV_32FC1 types are supported.\n",
      "    \n",
      "    createStereoConstantSpaceBP(...)\n",
      "        createStereoConstantSpaceBP([, ndisp[, iters[, levels[, nr_plane[, msg_type]]]]]) -> retval\n",
      "        .   @brief Creates StereoConstantSpaceBP object.\n",
      "        .   \n",
      "        .   @param ndisp Number of disparities.\n",
      "        .   @param iters Number of BP iterations on each level.\n",
      "        .   @param levels Number of levels.\n",
      "        .   @param nr_plane Number of disparity levels on the first level.\n",
      "        .   @param msg_type Type for messages. CV_16SC1 and CV_32FC1 types are supported.\n",
      "    \n",
      "    createTemplateMatching(...)\n",
      "        createTemplateMatching(srcType, method[, user_block_size]) -> retval\n",
      "        .   @brief Creates implementation for cuda::TemplateMatching .\n",
      "        .   \n",
      "        .   @param srcType Input source type. CV_32F and CV_8U depth images (1..4 channels) are supported\n",
      "        .   for now.\n",
      "        .   @param method Specifies the way to compare the template with the image.\n",
      "        .   @param user_block_size You can use field user_block_size to set specific block size. If you\n",
      "        .   leave its default value Size(0,0) then automatic estimation of block size will be used (which is\n",
      "        .   optimized for speed). By varying user_block_size you can reduce memory requirements at the cost\n",
      "        .   of speed.\n",
      "        .   \n",
      "        .   The following methods are supported for the CV_8U depth images for now:\n",
      "        .   \n",
      "        .   -   CV_TM_SQDIFF\n",
      "        .   -   CV_TM_SQDIFF_NORMED\n",
      "        .   -   CV_TM_CCORR\n",
      "        .   -   CV_TM_CCORR_NORMED\n",
      "        .   -   CV_TM_CCOEFF\n",
      "        .   -   CV_TM_CCOEFF_NORMED\n",
      "        .   \n",
      "        .   The following methods are supported for the CV_32F images for now:\n",
      "        .   \n",
      "        .   -   CV_TM_SQDIFF\n",
      "        .   -   CV_TM_CCORR\n",
      "        .   \n",
      "        .   @sa matchTemplate\n",
      "    \n",
      "    cvtColor(...)\n",
      "        cvtColor(src, code[, dst[, dcn[, stream]]]) -> dst\n",
      "        .   @brief Converts an image from one color space to another.\n",
      "        .   \n",
      "        .   @param src Source image with CV_8U , CV_16U , or CV_32F depth and 1, 3, or 4 channels.\n",
      "        .   @param dst Destination image.\n",
      "        .   @param code Color space conversion code. For details, see cvtColor .\n",
      "        .   @param dcn Number of channels in the destination image. If the parameter is 0, the number of the\n",
      "        .   channels is derived automatically from src and the code .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   3-channel color spaces (like HSV, XYZ, and so on) can be stored in a 4-channel image for better\n",
      "        .   performance.\n",
      "        .   \n",
      "        .   @sa cvtColor\n",
      "    \n",
      "    demosaicing(...)\n",
      "        demosaicing(src, code[, dst[, dcn[, stream]]]) -> dst\n",
      "        .   @brief Converts an image from Bayer pattern to RGB or grayscale.\n",
      "        .   \n",
      "        .   @param src Source image (8-bit or 16-bit single channel).\n",
      "        .   @param dst Destination image.\n",
      "        .   @param code Color space conversion code (see the description below).\n",
      "        .   @param dcn Number of channels in the destination image. If the parameter is 0, the number of the\n",
      "        .   channels is derived automatically from src and the code .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function can do the following transformations:\n",
      "        .   \n",
      "        .   -   Demosaicing using bilinear interpolation\n",
      "        .   \n",
      "        .   > -   COLOR_BayerBG2GRAY , COLOR_BayerGB2GRAY , COLOR_BayerRG2GRAY , COLOR_BayerGR2GRAY\n",
      "        .   > -   COLOR_BayerBG2BGR , COLOR_BayerGB2BGR , COLOR_BayerRG2BGR , COLOR_BayerGR2BGR\n",
      "        .   \n",
      "        .   -   Demosaicing using Malvar-He-Cutler algorithm (@cite MHT2011)\n",
      "        .   \n",
      "        .   > -   COLOR_BayerBG2GRAY_MHT , COLOR_BayerGB2GRAY_MHT , COLOR_BayerRG2GRAY_MHT ,\n",
      "        .   >     COLOR_BayerGR2GRAY_MHT\n",
      "        .   > -   COLOR_BayerBG2BGR_MHT , COLOR_BayerGB2BGR_MHT , COLOR_BayerRG2BGR_MHT ,\n",
      "        .   >     COLOR_BayerGR2BGR_MHT\n",
      "        .   \n",
      "        .   @sa cvtColor\n",
      "    \n",
      "    dft(...)\n",
      "        dft(src, dft_size[, dst[, flags[, stream]]]) -> dst\n",
      "        .   @brief Performs a forward or inverse discrete Fourier transform (1D or 2D) of the floating point matrix.\n",
      "        .   \n",
      "        .   @param src Source matrix (real or complex).\n",
      "        .   @param dst Destination matrix (real or complex).\n",
      "        .   @param dft_size Size of a discrete Fourier transform.\n",
      "        .   @param flags Optional flags:\n",
      "        .   -   **DFT_ROWS** transforms each individual row of the source matrix.\n",
      "        .   -   **DFT_SCALE** scales the result: divide it by the number of elements in the transform\n",
      "        .   (obtained from dft_size ).\n",
      "        .   -   **DFT_INVERSE** inverts DFT. Use for complex-complex cases (real-complex and complex-real\n",
      "        .   cases are always forward and inverse, respectively).\n",
      "        .   -   **DFT_COMPLEX_INPUT** Specifies that input is complex input with 2 channels.\n",
      "        .   -   **DFT_REAL_OUTPUT** specifies the output as real. The source matrix is the result of\n",
      "        .   real-complex transform, so the destination matrix must be real.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   Use to handle real matrices ( CV32FC1 ) and complex matrices in the interleaved format ( CV32FC2 ).\n",
      "        .   \n",
      "        .   The source matrix should be continuous, otherwise reallocation and data copying is performed. The\n",
      "        .   function chooses an operation mode depending on the flags, size, and channel count of the source\n",
      "        .   matrix:\n",
      "        .   \n",
      "        .   -   If the source matrix is complex and the output is not specified as real, the destination\n",
      "        .   matrix is complex and has the dft_size size and CV_32FC2 type. The destination matrix\n",
      "        .   contains a full result of the DFT (forward or inverse).\n",
      "        .   -   If the source matrix is complex and the output is specified as real, the function assumes that\n",
      "        .   its input is the result of the forward transform (see the next item). The destination matrix\n",
      "        .   has the dft_size size and CV_32FC1 type. It contains the result of the inverse DFT.\n",
      "        .   -   If the source matrix is real (its type is CV_32FC1 ), forward DFT is performed. The result of\n",
      "        .   the DFT is packed into complex ( CV_32FC2 ) matrix. So, the width of the destination matrix\n",
      "        .   is dft_size.width / 2 + 1 . But if the source is a single column, the height is reduced\n",
      "        .   instead of the width.\n",
      "        .   \n",
      "        .   @sa dft\n",
      "    \n",
      "    divide(...)\n",
      "        divide(src1, src2[, dst[, scale[, dtype[, stream]]]]) -> dst\n",
      "        .   @brief Computes a matrix-matrix or matrix-scalar division.\n",
      "        .   \n",
      "        .   @param src1 First source matrix or a scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and number of channels as the input array(s).\n",
      "        .   The depth is defined by dtype or src1 depth.\n",
      "        .   @param scale Optional scale factor.\n",
      "        .   @param dtype Optional depth of the output array.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   This function, in contrast to divide, uses a round-down rounding mode.\n",
      "        .   \n",
      "        .   @sa divide\n",
      "    \n",
      "    drawColorDisp(...)\n",
      "        drawColorDisp(src_disp, ndisp[, dst_disp[, stream]]) -> dst_disp\n",
      "        .   @brief Colors a disparity image.\n",
      "        .   \n",
      "        .   @param src_disp Input single-channel 8-bit unsigned, 16-bit signed, 32-bit signed or 32-bit\n",
      "        .   floating-point disparity image. If 16-bit signed format is used, the values are assumed to have no\n",
      "        .   fractional bits.\n",
      "        .   @param dst_disp Output disparity image. It has the same size as src_disp. The type is CV_8UC4\n",
      "        .   in BGRA format (alpha = 255).\n",
      "        .   @param ndisp Number of disparities.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   This function draws a colored disparity map by converting disparity values from [0..ndisp) interval\n",
      "        .   first to HSV color space (where different disparity values correspond to different hues) and then\n",
      "        .   converting the pixels to RGB for visualization.\n",
      "    \n",
      "    ensureSizeIsEnough(...)\n",
      "        ensureSizeIsEnough(rows, cols, type[, arr]) -> arr\n",
      "        .   @brief Ensures that the size of a matrix is big enough and the matrix has a proper type.\n",
      "        .   \n",
      "        .   @param rows Minimum desired number of rows.\n",
      "        .   @param cols Minimum desired number of columns.\n",
      "        .   @param type Desired matrix type.\n",
      "        .   @param arr Destination matrix.\n",
      "        .   \n",
      "        .   The function does not reallocate memory if the matrix has proper attributes already.\n",
      "    \n",
      "    equalizeHist(...)\n",
      "        equalizeHist(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Equalizes the histogram of a grayscale image.\n",
      "        .   \n",
      "        .   @param src Source image with CV_8UC1 type.\n",
      "        .   @param dst Destination image.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa equalizeHist\n",
      "    \n",
      "    evenLevels(...)\n",
      "        evenLevels(nLevels, lowerLevel, upperLevel[, levels[, stream]]) -> levels\n",
      "        .   @brief Computes levels with even distribution.\n",
      "        .   \n",
      "        .   @param levels Destination array. levels has 1 row, nLevels columns, and the CV_32SC1 type.\n",
      "        .   @param nLevels Number of computed levels. nLevels must be at least 2.\n",
      "        .   @param lowerLevel Lower boundary value of the lowest level.\n",
      "        .   @param upperLevel Upper boundary value of the greatest level.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    exp(...)\n",
      "        exp(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes an exponent of each matrix element.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa exp\n",
      "    \n",
      "    findMinMax(...)\n",
      "        findMinMax(src[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    findMinMaxLoc(...)\n",
      "        findMinMaxLoc(src[, minMaxVals[, loc[, mask[, stream]]]]) -> minMaxVals, loc\n",
      "        .   @overload\n",
      "    \n",
      "    flip(...)\n",
      "        flip(src, flipCode[, dst[, stream]]) -> dst\n",
      "        .   @brief Flips a 2D matrix around vertical, horizontal, or both axes.\n",
      "        .   \n",
      "        .   @param src Source matrix. Supports 1, 3 and 4 channels images with CV_8U, CV_16U, CV_32S or\n",
      "        .   CV_32F depth.\n",
      "        .   @param dst Destination matrix.\n",
      "        .   @param flipCode Flip mode for the source:\n",
      "        .   -   0 Flips around x-axis.\n",
      "        .   -   \\> 0 Flips around y-axis.\n",
      "        .   -   \\< 0 Flips around both axes.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa flip\n",
      "    \n",
      "    gammaCorrection(...)\n",
      "        gammaCorrection(src[, dst[, forward[, stream]]]) -> dst\n",
      "        .   @brief Routines for correcting image color gamma.\n",
      "        .   \n",
      "        .   @param src Source image (3- or 4-channel 8 bit).\n",
      "        .   @param dst Destination image.\n",
      "        .   @param forward true for forward gamma correction or false for inverse gamma correction.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    gemm(...)\n",
      "        gemm(src1, src2, alpha, src3, beta[, dst[, flags[, stream]]]) -> dst\n",
      "        .   @brief Performs generalized matrix multiplication.\n",
      "        .   \n",
      "        .   @param src1 First multiplied input matrix that should have CV_32FC1 , CV_64FC1 , CV_32FC2 , or\n",
      "        .   CV_64FC2 type.\n",
      "        .   @param src2 Second multiplied input matrix of the same type as src1 .\n",
      "        .   @param alpha Weight of the matrix product.\n",
      "        .   @param src3 Third optional delta matrix added to the matrix product. It should have the same type\n",
      "        .   as src1 and src2 .\n",
      "        .   @param beta Weight of src3 .\n",
      "        .   @param dst Destination matrix. It has the proper size and the same type as input matrices.\n",
      "        .   @param flags Operation flags:\n",
      "        .   -   **GEMM_1_T** transpose src1\n",
      "        .   -   **GEMM_2_T** transpose src2\n",
      "        .   -   **GEMM_3_T** transpose src3\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function performs generalized matrix multiplication similar to the gemm functions in BLAS level\n",
      "        .   3. For example, gemm(src1, src2, alpha, src3, beta, dst, GEMM_1_T + GEMM_3_T) corresponds to\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} =  \\texttt{alpha} \\cdot \\texttt{src1} ^T  \\cdot \\texttt{src2} +  \\texttt{beta} \\cdot \\texttt{src3} ^T\\f]\n",
      "        .   \n",
      "        .   @note Transposition operation doesn't support CV_64FC2 input type.\n",
      "        .   \n",
      "        .   @sa gemm\n",
      "    \n",
      "    getCudaEnabledDeviceCount(...)\n",
      "        getCudaEnabledDeviceCount() -> retval\n",
      "        .   @brief Returns the number of installed CUDA-enabled devices.\n",
      "        .   \n",
      "        .   Use this function before any other CUDA functions calls. If OpenCV is compiled without CUDA support,\n",
      "        .   this function returns 0. If the CUDA driver is not installed, or is incompatible, this function\n",
      "        .   returns -1.\n",
      "    \n",
      "    getDevice(...)\n",
      "        getDevice() -> retval\n",
      "        .   @brief Returns the current device index set by cuda::setDevice or initialized by default.\n",
      "    \n",
      "    histEven(...)\n",
      "        histEven(src, histSize, lowerLevel, upperLevel[, hist[, stream]]) -> hist\n",
      "        .   @brief Calculates a histogram with evenly distributed bins.\n",
      "        .   \n",
      "        .   @param src Source image. CV_8U, CV_16U, or CV_16S depth and 1 or 4 channels are supported. For\n",
      "        .   a four-channel image, all channels are processed separately.\n",
      "        .   @param hist Destination histogram with one row, histSize columns, and the CV_32S type.\n",
      "        .   @param histSize Size of the histogram.\n",
      "        .   @param lowerLevel Lower boundary of lowest-level bin.\n",
      "        .   @param upperLevel Upper boundary of highest-level bin.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        \n",
      "        \n",
      "        \n",
      "        histEven(src, hist, histSize, lowerLevel, upperLevel[, stream]) -> None\n",
      "        .   @overload\n",
      "    \n",
      "    histRange(...)\n",
      "        histRange(src, levels[, hist[, stream]]) -> hist\n",
      "        .   @brief Calculates a histogram with bins determined by the levels array.\n",
      "        .   \n",
      "        .   @param src Source image. CV_8U , CV_16U , or CV_16S depth and 1 or 4 channels are supported.\n",
      "        .   For a four-channel image, all channels are processed separately.\n",
      "        .   @param hist Destination histogram with one row, (levels.cols-1) columns, and the CV_32SC1 type.\n",
      "        .   @param levels Number of levels in the histogram.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        \n",
      "        \n",
      "        \n",
      "        histRange(src, hist, levels[, stream]) -> None\n",
      "        .   @overload\n",
      "    \n",
      "    integral(...)\n",
      "        integral(src[, sum[, stream]]) -> sum\n",
      "        .   @brief Computes an integral image.\n",
      "        .   \n",
      "        .   @param src Source image. Only CV_8UC1 images are supported for now.\n",
      "        .   @param sum Integral image containing 32-bit unsigned integer values packed into CV_32SC1 .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa integral\n",
      "    \n",
      "    log(...)\n",
      "        log(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes a natural logarithm of absolute value of each matrix element.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa log\n",
      "    \n",
      "    magnitude(...)\n",
      "        magnitude(xy[, magnitude[, stream]]) -> magnitude\n",
      "        .   @brief Computes magnitudes of complex matrix elements.\n",
      "        .   \n",
      "        .   @param xy Source complex matrix in the interleaved format ( CV_32FC2 ).\n",
      "        .   @param magnitude Destination matrix of float magnitudes ( CV_32FC1 ).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa magnitude\n",
      "        \n",
      "        \n",
      "        \n",
      "        magnitude(x, y[, magnitude[, stream]]) -> magnitude\n",
      "        .   @overload\n",
      "        .   computes magnitude of each (x(i), y(i)) vector\n",
      "        .   supports only floating-point source\n",
      "        .   @param x Source matrix containing real components ( CV_32FC1 ).\n",
      "        .   @param y Source matrix containing imaginary components ( CV_32FC1 ).\n",
      "        .   @param magnitude Destination matrix of float magnitudes ( CV_32FC1 ).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    magnitudeSqr(...)\n",
      "        magnitudeSqr(xy[, magnitude[, stream]]) -> magnitude\n",
      "        .   @brief Computes squared magnitudes of complex matrix elements.\n",
      "        .   \n",
      "        .   @param xy Source complex matrix in the interleaved format ( CV_32FC2 ).\n",
      "        .   @param magnitude Destination matrix of float magnitude squares ( CV_32FC1 ).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        \n",
      "        \n",
      "        \n",
      "        magnitudeSqr(x, y[, magnitude[, stream]]) -> magnitude\n",
      "        .   @overload\n",
      "        .   computes squared magnitude of each (x(i), y(i)) vector\n",
      "        .   supports only floating-point source\n",
      "        .   @param x Source matrix containing real components ( CV_32FC1 ).\n",
      "        .   @param y Source matrix containing imaginary components ( CV_32FC1 ).\n",
      "        .   @param magnitude Destination matrix of float magnitude squares ( CV_32FC1 ).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    max(...)\n",
      "        max(src1, src2[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes the per-element maximum of two matrices (or a matrix and a scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa max\n",
      "    \n",
      "    meanShiftFiltering(...)\n",
      "        meanShiftFiltering(src, sp, sr[, dst[, criteria[, stream]]]) -> dst\n",
      "        .   @brief Performs mean-shift filtering for each point of the source image.\n",
      "        .   \n",
      "        .   @param src Source image. Only CV_8UC4 images are supported for now.\n",
      "        .   @param dst Destination image containing the color of mapped points. It has the same size and type\n",
      "        .   as src .\n",
      "        .   @param sp Spatial window radius.\n",
      "        .   @param sr Color window radius.\n",
      "        .   @param criteria Termination criteria. See TermCriteria.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   It maps each point of the source image into another point. As a result, you have a new color and new\n",
      "        .   position of each point.\n",
      "    \n",
      "    meanShiftProc(...)\n",
      "        meanShiftProc(src, sp, sr[, dstr[, dstsp[, criteria[, stream]]]]) -> dstr, dstsp\n",
      "        .   @brief Performs a mean-shift procedure and stores information about processed points (their colors and\n",
      "        .   positions) in two images.\n",
      "        .   \n",
      "        .   @param src Source image. Only CV_8UC4 images are supported for now.\n",
      "        .   @param dstr Destination image containing the color of mapped points. The size and type is the same\n",
      "        .   as src .\n",
      "        .   @param dstsp Destination image containing the position of mapped points. The size is the same as\n",
      "        .   src size. The type is CV_16SC2 .\n",
      "        .   @param sp Spatial window radius.\n",
      "        .   @param sr Color window radius.\n",
      "        .   @param criteria Termination criteria. See TermCriteria.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa cuda::meanShiftFiltering\n",
      "    \n",
      "    meanShiftSegmentation(...)\n",
      "        meanShiftSegmentation(src, sp, sr, minsize[, dst[, criteria[, stream]]]) -> dst\n",
      "        .   @brief Performs a mean-shift segmentation of the source image and eliminates small segments.\n",
      "        .   \n",
      "        .   @param src Source image. Only CV_8UC4 images are supported for now.\n",
      "        .   @param dst Segmented image with the same size and type as src (host or gpu memory).\n",
      "        .   @param sp Spatial window radius.\n",
      "        .   @param sr Color window radius.\n",
      "        .   @param minsize Minimum segment size. Smaller segments are merged.\n",
      "        .   @param criteria Termination criteria. See TermCriteria.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    meanStdDev(...)\n",
      "        meanStdDev(mtx, mean, stddev) -> None\n",
      "        .   @brief Computes a mean value and a standard deviation of matrix elements.\n",
      "        .   \n",
      "        .   @param mtx Source matrix. CV_8UC1 matrices are supported for now.\n",
      "        .   @param mean Mean value.\n",
      "        .   @param stddev Standard deviation value.\n",
      "        .   \n",
      "        .   @sa meanStdDev\n",
      "        \n",
      "        \n",
      "        \n",
      "        meanStdDev(mtx[, dst[, stream]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    merge(...)\n",
      "        merge(src, n[, dst[, stream]]) -> dst\n",
      "        .   @brief Makes a multi-channel matrix out of several single-channel matrices.\n",
      "        .   \n",
      "        .   @param src Array/vector of source matrices.\n",
      "        .   @param n Number of source matrices.\n",
      "        .   @param dst Destination matrix.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa merge\n",
      "        \n",
      "        \n",
      "        \n",
      "        merge(src[, dst[, stream]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    min(...)\n",
      "        min(src1, src2[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes the per-element minimum of two matrices (or a matrix and a scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa min\n",
      "    \n",
      "    minMax(...)\n",
      "        minMax(src, minVal, maxVal[, mask]) -> None\n",
      "        .   @brief Finds global minimum and maximum matrix elements and returns their values.\n",
      "        .   \n",
      "        .   @param src Single-channel source image.\n",
      "        .   @param minVal Pointer to the returned minimum value. Use NULL if not required.\n",
      "        .   @param maxVal Pointer to the returned maximum value. Use NULL if not required.\n",
      "        .   @param mask Optional mask to select a sub-matrix.\n",
      "        .   \n",
      "        .   The function does not work with CV_64F images on GPUs with the compute capability \\< 1.3.\n",
      "        .   \n",
      "        .   @sa minMaxLoc\n",
      "    \n",
      "    minMaxLoc(...)\n",
      "        minMaxLoc(src, minVal, maxVal, minLoc, maxLoc[, mask]) -> None\n",
      "        .   @brief Finds global minimum and maximum matrix elements and returns their values with locations.\n",
      "        .   \n",
      "        .   @param src Single-channel source image.\n",
      "        .   @param minVal Pointer to the returned minimum value. Use NULL if not required.\n",
      "        .   @param maxVal Pointer to the returned maximum value. Use NULL if not required.\n",
      "        .   @param minLoc Pointer to the returned minimum location. Use NULL if not required.\n",
      "        .   @param maxLoc Pointer to the returned maximum location. Use NULL if not required.\n",
      "        .   @param mask Optional mask to select a sub-matrix.\n",
      "        .   \n",
      "        .   The function does not work with CV_64F images on GPU with the compute capability \\< 1.3.\n",
      "        .   \n",
      "        .   @sa minMaxLoc\n",
      "    \n",
      "    mulAndScaleSpectrums(...)\n",
      "        mulAndScaleSpectrums(src1, src2, flags, scale[, dst[, conjB[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element multiplication of two Fourier spectrums and scales the result.\n",
      "        .   \n",
      "        .   @param src1 First spectrum.\n",
      "        .   @param src2 Second spectrum with the same size and type as a .\n",
      "        .   @param dst Destination spectrum.\n",
      "        .   @param flags Mock parameter used for CPU/CUDA interfaces similarity, simply add a `0` value.\n",
      "        .   @param scale Scale constant.\n",
      "        .   @param conjB Optional flag to specify if the second spectrum needs to be conjugated before the\n",
      "        .   multiplication.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   Only full (not packed) CV_32FC2 complex spectrums in the interleaved format are supported for now.\n",
      "        .   \n",
      "        .   @sa mulSpectrums\n",
      "    \n",
      "    mulSpectrums(...)\n",
      "        mulSpectrums(src1, src2, flags[, dst[, conjB[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element multiplication of two Fourier spectrums.\n",
      "        .   \n",
      "        .   @param src1 First spectrum.\n",
      "        .   @param src2 Second spectrum with the same size and type as a .\n",
      "        .   @param dst Destination spectrum.\n",
      "        .   @param flags Mock parameter used for CPU/CUDA interfaces similarity.\n",
      "        .   @param conjB Optional flag to specify if the second spectrum needs to be conjugated before the\n",
      "        .   multiplication.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   Only full (not packed) CV_32FC2 complex spectrums in the interleaved format are supported for now.\n",
      "        .   \n",
      "        .   @sa mulSpectrums\n",
      "    \n",
      "    multiply(...)\n",
      "        multiply(src1, src2[, dst[, scale[, dtype[, stream]]]]) -> dst\n",
      "        .   @brief Computes a matrix-matrix or matrix-scalar per-element product.\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and number of channels as the input array(s).\n",
      "        .   The depth is defined by dtype or src1 depth.\n",
      "        .   @param scale Optional scale factor.\n",
      "        .   @param dtype Optional depth of the output array.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa multiply\n",
      "    \n",
      "    norm(...)\n",
      "        norm(src1, normType[, mask]) -> retval\n",
      "        .   @brief Returns the norm of a matrix (or difference of two matrices).\n",
      "        .   \n",
      "        .   @param src1 Source matrix. Any matrices except 64F are supported.\n",
      "        .   @param normType Norm type. NORM_L1 , NORM_L2 , and NORM_INF are supported for now.\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "        .   \n",
      "        .   @sa norm\n",
      "        \n",
      "        \n",
      "        \n",
      "        norm(src1, src2[, normType]) -> retval\n",
      "        .   @brief Returns the difference of two matrices.\n",
      "        .   \n",
      "        .   @param src1 Source matrix. Any matrices except 64F are supported.\n",
      "        .   @param src2 Second source matrix (if any) with the same size and type as src1.\n",
      "        .   @param normType Norm type. NORM_L1 , NORM_L2 , and NORM_INF are supported for now.\n",
      "        .   \n",
      "        .   @sa norm\n",
      "    \n",
      "    normalize(...)\n",
      "        normalize(src, alpha, beta, norm_type, dtype[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @brief Normalizes the norm or value range of an array.\n",
      "        .   \n",
      "        .   @param src Input array.\n",
      "        .   @param dst Output array of the same size as src .\n",
      "        .   @param alpha Norm value to normalize to or the lower range boundary in case of the range\n",
      "        .   normalization.\n",
      "        .   @param beta Upper range boundary in case of the range normalization; it is not used for the norm\n",
      "        .   normalization.\n",
      "        .   @param norm_type Normalization type ( NORM_MINMAX , NORM_L2 , NORM_L1 or NORM_INF ).\n",
      "        .   @param dtype When negative, the output array has the same type as src; otherwise, it has the same\n",
      "        .   number of channels as src and the depth =CV_MAT_DEPTH(dtype).\n",
      "        .   @param mask Optional operation mask.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa normalize\n",
      "    \n",
      "    phase(...)\n",
      "        phase(x, y[, angle[, angleInDegrees[, stream]]]) -> angle\n",
      "        .   @brief Computes polar angles of complex matrix elements.\n",
      "        .   \n",
      "        .   @param x Source matrix containing real components ( CV_32FC1 ).\n",
      "        .   @param y Source matrix containing imaginary components ( CV_32FC1 ).\n",
      "        .   @param angle Destination matrix of angles ( CV_32FC1 ).\n",
      "        .   @param angleInDegrees Flag for angles that must be evaluated in degrees.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa phase\n",
      "    \n",
      "    polarToCart(...)\n",
      "        polarToCart(magnitude, angle[, x[, y[, angleInDegrees[, stream]]]]) -> x, y\n",
      "        .   @brief Converts polar coordinates into Cartesian.\n",
      "        .   \n",
      "        .   @param magnitude Source matrix containing magnitudes ( CV_32FC1 or CV_64FC1 ).\n",
      "        .   @param angle Source matrix containing angles ( same type as magnitude ).\n",
      "        .   @param x Destination matrix of real components ( same type as magnitude ).\n",
      "        .   @param y Destination matrix of imaginary components ( same type as magnitude ).\n",
      "        .   @param angleInDegrees Flag that indicates angles in degrees.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    pow(...)\n",
      "        pow(src, power[, dst[, stream]]) -> dst\n",
      "        .   @brief Raises every matrix element to a power.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param power Exponent of power.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function pow raises every element of the input matrix to power :\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (I) =  \\fork{\\texttt{src}(I)^power}{if \\texttt{power} is integer}{|\\texttt{src}(I)|^power}{otherwise}\\f]\n",
      "        .   \n",
      "        .   @sa pow\n",
      "    \n",
      "    printCudaDeviceInfo(...)\n",
      "        printCudaDeviceInfo(device) -> None\n",
      "        .\n",
      "    \n",
      "    printShortCudaDeviceInfo(...)\n",
      "        printShortCudaDeviceInfo(device) -> None\n",
      "        .\n",
      "    \n",
      "    pyrDown(...)\n",
      "        pyrDown(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Smoothes an image and downsamples it.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image. Will have Size((src.cols+1)/2, (src.rows+1)/2) size and the same\n",
      "        .   type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa pyrDown\n",
      "    \n",
      "    pyrUp(...)\n",
      "        pyrUp(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Upsamples an image and then smoothes it.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image. Will have Size(src.cols\\*2, src.rows\\*2) size and the same type as\n",
      "        .   src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    rectStdDev(...)\n",
      "        rectStdDev(src, sqr, rect[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes a standard deviation of integral images.\n",
      "        .   \n",
      "        .   @param src Source image. Only the CV_32SC1 type is supported.\n",
      "        .   @param sqr Squared source image. Only the CV_32FC1 type is supported.\n",
      "        .   @param dst Destination image with the same type and size as src .\n",
      "        .   @param rect Rectangular window.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    reduce(...)\n",
      "        reduce(mtx, dim, reduceOp[, vec[, dtype[, stream]]]) -> vec\n",
      "        .   @brief Reduces a matrix to a vector.\n",
      "        .   \n",
      "        .   @param mtx Source 2D matrix.\n",
      "        .   @param vec Destination vector. Its size and type is defined by dim and dtype parameters.\n",
      "        .   @param dim Dimension index along which the matrix is reduced. 0 means that the matrix is reduced\n",
      "        .   to a single row. 1 means that the matrix is reduced to a single column.\n",
      "        .   @param reduceOp Reduction operation that could be one of the following:\n",
      "        .   -   **CV_REDUCE_SUM** The output is the sum of all rows/columns of the matrix.\n",
      "        .   -   **CV_REDUCE_AVG** The output is the mean vector of all rows/columns of the matrix.\n",
      "        .   -   **CV_REDUCE_MAX** The output is the maximum (column/row-wise) of all rows/columns of the\n",
      "        .   matrix.\n",
      "        .   -   **CV_REDUCE_MIN** The output is the minimum (column/row-wise) of all rows/columns of the\n",
      "        .   matrix.\n",
      "        .   @param dtype When it is negative, the destination vector will have the same type as the source\n",
      "        .   matrix. Otherwise, its type will be CV_MAKE_TYPE(CV_MAT_DEPTH(dtype), mtx.channels()) .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function reduce reduces the matrix to a vector by treating the matrix rows/columns as a set of\n",
      "        .   1D vectors and performing the specified operation on the vectors until a single row/column is\n",
      "        .   obtained. For example, the function can be used to compute horizontal and vertical projections of a\n",
      "        .   raster image. In case of CV_REDUCE_SUM and CV_REDUCE_AVG , the output may have a larger element\n",
      "        .   bit-depth to preserve accuracy. And multi-channel arrays are also supported in these two reduction\n",
      "        .   modes.\n",
      "        .   \n",
      "        .   @sa reduce\n",
      "    \n",
      "    registerPageLocked(...)\n",
      "        registerPageLocked(m) -> None\n",
      "        .   @brief Page-locks the memory of matrix and maps it for the device(s).\n",
      "        .   \n",
      "        .   @param m Input matrix.\n",
      "    \n",
      "    remap(...)\n",
      "        remap(src, xmap, ymap, interpolation[, dst[, borderMode[, borderValue[, stream]]]]) -> dst\n",
      "        .   @brief Applies a generic geometrical transformation to an image.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image with the size the same as xmap and the type the same as src .\n",
      "        .   @param xmap X values. Only CV_32FC1 type is supported.\n",
      "        .   @param ymap Y values. Only CV_32FC1 type is supported.\n",
      "        .   @param interpolation Interpolation method (see resize ). INTER_NEAREST , INTER_LINEAR and\n",
      "        .   INTER_CUBIC are supported for now.\n",
      "        .   @param borderMode Pixel extrapolation method (see borderInterpolate ). BORDER_REFLECT101 ,\n",
      "        .   BORDER_REPLICATE , BORDER_CONSTANT , BORDER_REFLECT and BORDER_WRAP are supported for now.\n",
      "        .   @param borderValue Value used in case of a constant border. By default, it is 0.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function transforms the source image using the specified map:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\texttt{src} (xmap(x,y), ymap(x,y))\\f]\n",
      "        .   \n",
      "        .   Values of pixels with non-integer coordinates are computed using the bilinear interpolation.\n",
      "        .   \n",
      "        .   @sa remap\n",
      "    \n",
      "    reprojectImageTo3D(...)\n",
      "        reprojectImageTo3D(disp, Q[, xyzw[, dst_cn[, stream]]]) -> xyzw\n",
      "        .   @brief Reprojects a disparity image to 3D space.\n",
      "        .   \n",
      "        .   @param disp Input single-channel 8-bit unsigned, 16-bit signed, 32-bit signed or 32-bit\n",
      "        .   floating-point disparity image. If 16-bit signed format is used, the values are assumed to have no\n",
      "        .   fractional bits.\n",
      "        .   @param xyzw Output 3- or 4-channel floating-point image of the same size as disp . Each element of\n",
      "        .   xyzw(x,y) contains 3D coordinates (x,y,z) or (x,y,z,1) of the point (x,y) , computed from the\n",
      "        .   disparity map.\n",
      "        .   @param Q \\f$4 \\times 4\\f$ perspective transformation matrix that can be obtained via stereoRectify .\n",
      "        .   @param dst_cn The number of channels for output image. Can be 3 or 4.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa reprojectImageTo3D\n",
      "    \n",
      "    resetDevice(...)\n",
      "        resetDevice() -> None\n",
      "        .   @brief Explicitly destroys and cleans up all resources associated with the current device in the current\n",
      "        .   process.\n",
      "        .   \n",
      "        .   Any subsequent API call to this device will reinitialize the device.\n",
      "    \n",
      "    resize(...)\n",
      "        resize(src, dsize[, dst[, fx[, fy[, interpolation[, stream]]]]]) -> dst\n",
      "        .   @brief Resizes an image.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image with the same type as src . The size is dsize (when it is non-zero)\n",
      "        .   or the size is computed from src.size() , fx , and fy .\n",
      "        .   @param dsize Destination image size. If it is zero, it is computed as:\n",
      "        .   \\f[\\texttt{dsize = Size(round(fx*src.cols), round(fy*src.rows))}\\f]\n",
      "        .   Either dsize or both fx and fy must be non-zero.\n",
      "        .   @param fx Scale factor along the horizontal axis. If it is zero, it is computed as:\n",
      "        .   \\f[\\texttt{(double)dsize.width/src.cols}\\f]\n",
      "        .   @param fy Scale factor along the vertical axis. If it is zero, it is computed as:\n",
      "        .   \\f[\\texttt{(double)dsize.height/src.rows}\\f]\n",
      "        .   @param interpolation Interpolation method. INTER_NEAREST , INTER_LINEAR and INTER_CUBIC are\n",
      "        .   supported for now.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa resize\n",
      "    \n",
      "    rotate(...)\n",
      "        rotate(src, dsize, angle[, dst[, xShift[, yShift[, interpolation[, stream]]]]]) -> dst\n",
      "        .   @brief Rotates an image around the origin (0,0) and then shifts it.\n",
      "        .   \n",
      "        .   @param src Source image. Supports 1, 3 or 4 channels images with CV_8U , CV_16U or CV_32F\n",
      "        .   depth.\n",
      "        .   @param dst Destination image with the same type as src . The size is dsize .\n",
      "        .   @param dsize Size of the destination image.\n",
      "        .   @param angle Angle of rotation in degrees.\n",
      "        .   @param xShift Shift along the horizontal axis.\n",
      "        .   @param yShift Shift along the vertical axis.\n",
      "        .   @param interpolation Interpolation method. Only INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC\n",
      "        .   are supported.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa cuda::warpAffine\n",
      "    \n",
      "    setBufferPoolConfig(...)\n",
      "        setBufferPoolConfig(deviceId, stackSize, stackCount) -> None\n",
      "        .\n",
      "    \n",
      "    setBufferPoolUsage(...)\n",
      "        setBufferPoolUsage(on) -> None\n",
      "        .\n",
      "    \n",
      "    setDevice(...)\n",
      "        setDevice(device) -> None\n",
      "        .   @brief Sets a device and initializes it for the current thread.\n",
      "        .   \n",
      "        .   @param device System index of a CUDA device starting with 0.\n",
      "        .   \n",
      "        .   If the call of this function is omitted, a default device is initialized at the fist CUDA usage.\n",
      "    \n",
      "    split(...)\n",
      "        split(src, dst[, stream]) -> None\n",
      "        .   @brief Copies each plane of a multi-channel matrix into an array.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination array/vector of single-channel matrices.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa split\n",
      "    \n",
      "    sqr(...)\n",
      "        sqr(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes a square value of each matrix element.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    sqrIntegral(...)\n",
      "        sqrIntegral(src[, sqsum[, stream]]) -> sqsum\n",
      "        .   @brief Computes a squared integral image.\n",
      "        .   \n",
      "        .   @param src Source image. Only CV_8UC1 images are supported for now.\n",
      "        .   @param sqsum Squared integral image containing 64-bit unsigned integer values packed into\n",
      "        .   CV_64FC1 .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    sqrSum(...)\n",
      "        sqrSum(src[, mask]) -> retval\n",
      "        .   @brief Returns the squared sum of matrix elements.\n",
      "        .   \n",
      "        .   @param src Source image of any depth except for CV_64F .\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "    \n",
      "    sqrt(...)\n",
      "        sqrt(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes a square root of each matrix element.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa sqrt\n",
      "    \n",
      "    subtract(...)\n",
      "        subtract(src1, src2[, dst[, mask[, dtype[, stream]]]]) -> dst\n",
      "        .   @brief Computes a matrix-matrix or matrix-scalar difference.\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar. Matrix should have the same size and type as src1 .\n",
      "        .   @param dst Destination matrix that has the same size and number of channels as the input array(s).\n",
      "        .   The depth is defined by dtype or src1 depth.\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param dtype Optional depth of the output array.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa subtract\n",
      "    \n",
      "    sum(...)\n",
      "        sum(src[, mask]) -> retval\n",
      "        .   @brief Returns the sum of matrix elements.\n",
      "        .   \n",
      "        .   @param src Source image of any depth except for CV_64F .\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "        .   \n",
      "        .   @sa sum\n",
      "    \n",
      "    threshold(...)\n",
      "        threshold(src, thresh, maxval, type[, dst[, stream]]) -> retval, dst\n",
      "        .   @brief Applies a fixed-level threshold to each array element.\n",
      "        .   \n",
      "        .   @param src Source array (single-channel).\n",
      "        .   @param dst Destination array with the same size and type as src .\n",
      "        .   @param thresh Threshold value.\n",
      "        .   @param maxval Maximum value to use with THRESH_BINARY and THRESH_BINARY_INV threshold types.\n",
      "        .   @param type Threshold type. For details, see threshold . The THRESH_OTSU and THRESH_TRIANGLE\n",
      "        .   threshold types are not supported.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa threshold\n",
      "    \n",
      "    transpose(...)\n",
      "        transpose(src1[, dst[, stream]]) -> dst\n",
      "        .   @brief Transposes a matrix.\n",
      "        .   \n",
      "        .   @param src1 Source matrix. 1-, 4-, 8-byte element sizes are supported for now.\n",
      "        .   @param dst Destination matrix.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa transpose\n",
      "    \n",
      "    unregisterPageLocked(...)\n",
      "        unregisterPageLocked(m) -> None\n",
      "        .   @brief Unmaps the memory of matrix and makes it pageable again.\n",
      "        .   \n",
      "        .   @param m Input matrix.\n",
      "    \n",
      "    warpAffine(...)\n",
      "        warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue[, stream]]]]]) -> dst\n",
      "        .   @brief Applies an affine transformation to an image.\n",
      "        .   \n",
      "        .   @param src Source image. CV_8U , CV_16U , CV_32S , or CV_32F depth and 1, 3, or 4 channels are\n",
      "        .   supported.\n",
      "        .   @param dst Destination image with the same type as src . The size is dsize .\n",
      "        .   @param M *2x3* transformation matrix.\n",
      "        .   @param dsize Size of the destination image.\n",
      "        .   @param flags Combination of interpolation methods (see resize) and the optional flag\n",
      "        .   WARP_INVERSE_MAP specifying that M is an inverse transformation ( dst=\\>src ). Only\n",
      "        .   INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC interpolation methods are supported.\n",
      "        .   @param borderMode\n",
      "        .   @param borderValue\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa warpAffine\n",
      "    \n",
      "    warpPerspective(...)\n",
      "        warpPerspective(src, M, dsize[, dst[, flags[, borderMode[, borderValue[, stream]]]]]) -> dst\n",
      "        .   @brief Applies a perspective transformation to an image.\n",
      "        .   \n",
      "        .   @param src Source image. CV_8U , CV_16U , CV_32S , or CV_32F depth and 1, 3, or 4 channels are\n",
      "        .   supported.\n",
      "        .   @param dst Destination image with the same type as src . The size is dsize .\n",
      "        .   @param M *3x3* transformation matrix.\n",
      "        .   @param dsize Size of the destination image.\n",
      "        .   @param flags Combination of interpolation methods (see resize ) and the optional flag\n",
      "        .   WARP_INVERSE_MAP specifying that M is the inverse transformation ( dst =\\> src ). Only\n",
      "        .   INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC interpolation methods are supported.\n",
      "        .   @param borderMode\n",
      "        .   @param borderValue\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa warpPerspective\n",
      "\n",
      "DATA\n",
      "    ALPHA_ATOP = 3\n",
      "    ALPHA_ATOP_PREMUL = 9\n",
      "    ALPHA_IN = 1\n",
      "    ALPHA_IN_PREMUL = 7\n",
      "    ALPHA_OUT = 2\n",
      "    ALPHA_OUT_PREMUL = 8\n",
      "    ALPHA_OVER = 0\n",
      "    ALPHA_OVER_PREMUL = 6\n",
      "    ALPHA_PLUS = 5\n",
      "    ALPHA_PLUS_PREMUL = 11\n",
      "    ALPHA_PREMUL = 12\n",
      "    ALPHA_XOR = 4\n",
      "    ALPHA_XOR_PREMUL = 10\n",
      "    COLOR_BAYER_BG2BGR_MHT = 256\n",
      "    COLOR_BAYER_BG2GRAY_MHT = 260\n",
      "    COLOR_BAYER_BG2RGB_MHT = 258\n",
      "    COLOR_BAYER_GB2BGR_MHT = 257\n",
      "    COLOR_BAYER_GB2GRAY_MHT = 261\n",
      "    COLOR_BAYER_GB2RGB_MHT = 259\n",
      "    COLOR_BAYER_GR2BGR_MHT = 259\n",
      "    COLOR_BAYER_GR2GRAY_MHT = 263\n",
      "    COLOR_BAYER_GR2RGB_MHT = 257\n",
      "    COLOR_BAYER_RG2BGR_MHT = 258\n",
      "    COLOR_BAYER_RG2GRAY_MHT = 262\n",
      "    COLOR_BAYER_RG2RGB_MHT = 256\n",
      "    COLOR_BayerBG2BGR_MHT = 256\n",
      "    COLOR_BayerBG2GRAY_MHT = 260\n",
      "    COLOR_BayerBG2RGB_MHT = 258\n",
      "    COLOR_BayerGB2BGR_MHT = 257\n",
      "    COLOR_BayerGB2GRAY_MHT = 261\n",
      "    COLOR_BayerGB2RGB_MHT = 259\n",
      "    COLOR_BayerGR2BGR_MHT = 259\n",
      "    COLOR_BayerGR2GRAY_MHT = 263\n",
      "    COLOR_BayerGR2RGB_MHT = 257\n",
      "    COLOR_BayerRG2BGR_MHT = 258\n",
      "    COLOR_BayerRG2GRAY_MHT = 262\n",
      "    COLOR_BayerRG2RGB_MHT = 256\n",
      "    DEVICE_INFO_COMPUTE_MODE_DEFAULT = 0\n",
      "    DEVICE_INFO_COMPUTE_MODE_EXCLUSIVE = 1\n",
      "    DEVICE_INFO_COMPUTE_MODE_EXCLUSIVE_PROCESS = 3\n",
      "    DEVICE_INFO_COMPUTE_MODE_PROHIBITED = 2\n",
      "    DYNAMIC_PARALLELISM = 35\n",
      "    DeviceInfo_ComputeModeDefault = 0\n",
      "    DeviceInfo_ComputeModeExclusive = 1\n",
      "    DeviceInfo_ComputeModeExclusiveProcess = 3\n",
      "    DeviceInfo_ComputeModeProhibited = 2\n",
      "    EVENT_BLOCKING_SYNC = 1\n",
      "    EVENT_DEFAULT = 0\n",
      "    EVENT_DISABLE_TIMING = 2\n",
      "    EVENT_INTERPROCESS = 4\n",
      "    Event_BLOCKING_SYNC = 1\n",
      "    Event_DEFAULT = 0\n",
      "    Event_DISABLE_TIMING = 2\n",
      "    Event_INTERPROCESS = 4\n",
      "    FEATURE_SET_COMPUTE_10 = 10\n",
      "    FEATURE_SET_COMPUTE_11 = 11\n",
      "    FEATURE_SET_COMPUTE_12 = 12\n",
      "    FEATURE_SET_COMPUTE_13 = 13\n",
      "    FEATURE_SET_COMPUTE_20 = 20\n",
      "    FEATURE_SET_COMPUTE_21 = 21\n",
      "    FEATURE_SET_COMPUTE_30 = 30\n",
      "    FEATURE_SET_COMPUTE_32 = 32\n",
      "    FEATURE_SET_COMPUTE_35 = 35\n",
      "    FEATURE_SET_COMPUTE_50 = 50\n",
      "    GLOBAL_ATOMICS = 11\n",
      "    HOST_MEM_PAGE_LOCKED = 1\n",
      "    HOST_MEM_SHARED = 2\n",
      "    HOST_MEM_WRITE_COMBINED = 4\n",
      "    HostMem_PAGE_LOCKED = 1\n",
      "    HostMem_SHARED = 2\n",
      "    HostMem_WRITE_COMBINED = 4\n",
      "    NATIVE_DOUBLE = 13\n",
      "    SHARED_ATOMICS = 12\n",
      "    SURF_CUDA_ANGLE_ROW = 5\n",
      "    SURF_CUDA_HESSIAN_ROW = 6\n",
      "    SURF_CUDA_LAPLACIAN_ROW = 2\n",
      "    SURF_CUDA_OCTAVE_ROW = 3\n",
      "    SURF_CUDA_ROWS_COUNT = 7\n",
      "    SURF_CUDA_SIZE_ROW = 4\n",
      "    SURF_CUDA_X_ROW = 0\n",
      "    SURF_CUDA_Y_ROW = 1\n",
      "    WARP_SHUFFLE_FUNCTIONS = 30\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cuda' has no attribute 'VideoReader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-cf4401971c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mvid_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mVidstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mexpstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVidstart_time\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'E:\\FFOutput\\C100~2.mov'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvid_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cuda' has no attribute 'VideoReader'"
     ]
    }
   ],
   "source": [
    "def grab_frame(cap):\n",
    "    ret,frame = cap.read()\n",
    "    return cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "def update_image(j):\n",
    "    cap.set(1,(slider2.value*fps)+j)\n",
    "    im2.set_data(grab_frame(cap))\n",
    "    \n",
    "fps=20\n",
    "xmin=max(min(HRdata.index),Vidstart_time)\n",
    "xmax=max(HRdata.index)\n",
    "x1=xmin\n",
    "x2=x1+delta\n",
    "frame=5*fps\n",
    "vid_start=((xmin-Vidstart_time).seconds)*fps\n",
    "expstart=Vidstart_time+delta\n",
    "cap = cv2.VideoCapture(r'E:\\FFOutput\\C100~2.mov')\n",
    "cap.set(1,vid_start)\n",
    "\n",
    "max_val=(max(HRdata.index)-min(HRdata.index)).seconds\n",
    "#create two subplots\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "gs  = gridspec.GridSpec(4, 1, height_ratios=[4, 1 ,1, 1])\n",
    "ax2 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[3])\n",
    "ax3 = plt.subplot(gs[2])\n",
    "ax4 = plt.subplot(gs[1])\n",
    "\n",
    "#ax1=fig.add_subplot(3,1,3)\n",
    "ax1.plot(HRdata.index,HRdata.HR,'b',linestyle='-',label='HR')\n",
    "ax1.plot(HRdata.index,HRdata.BR,'r',linestyle='-',label='BR')\n",
    "ax3.plot(data.index,data['Stress response'],marker='x',markersize=12,label='Stressor')\n",
    "ax4.plot(EDA.index,EDA.EDA,label='EDA')\n",
    "#ax1.axvline(linewidth=4, color='r')\n",
    "ax1.axvline(x=expstart,linewidth=4,color='r')\n",
    "ax4.axvline(x=expstart,linewidth=4,color='r')\n",
    "ax3.axvline(x=expstart,linewidth=4,color='r')\n",
    "ax2.axis('off')\n",
    "#create two image plots\n",
    "#im1 = ax1.imshow(grab_frame(cap1))\n",
    "im2 = ax2.imshow(grab_frame(cap))\n",
    "ax1.legend()\n",
    "ax1.set_title('Zephyr HR,BR and EDA HR')\n",
    "ax3.set_title('Stress response')  \n",
    "ax4.set_title('EDA')  \n",
    "ax1.get_shared_x_axes().join(ax1, ax3,ax4)\n",
    "#ax1.get_shared_x_axes().join(ax1, ax4)\n",
    "ax1.set_xlim(0,10)\n",
    "ax3.axes.get_xaxis().set_visible(False)\n",
    "ax4.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "#file=open('FigureObject.fig.pickle', 'wb')\n",
    "#pickle.dump(fig, file)\n",
    "#file.close\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def update_image(j):\n",
    "    #print(j)\n",
    "    global x1,x2\n",
    "    #if j<(slider3.value*fps):\n",
    "        #print(\"Updaing \",j)\n",
    "    im2 = ax2.imshow(inF[vid_start+((x1-xmin).seconds*fps)+j])\n",
    "\"\"\"\n",
    "ani1 = FuncAnimation(plt.gcf(), update_image, frames=15*20, interval=20/20,repeat=True)\n",
    "\n",
    "\n",
    "\n",
    "def update_axis(w,s):\n",
    "    global xmin,xmax,x1,x2,frame_rate,frame\n",
    "    delta_w=timedelta(seconds=w)\n",
    "    delta_s=timedelta(seconds=s)\n",
    "    x1=xmin+delta_w\n",
    "    x2=min(xmin+delta_w+delta_s,xmax)\n",
    "    ax1.set_xlim(x1,x2)\n",
    "    fig.canvas.draw_idle()\n",
    "    #ani1.event_source.stop()\n",
    "\n",
    "slider3=IntSlider(min=1, max=max_val, step=1, value=5,description='Zoom')\n",
    "slider2=IntSlider(min=0, max=max_val, step=1, value=0,description='Pan')\n",
    "interact(update_axis, w=slider2,s=slider3);    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "#HTML(ani.to_jshtml())\n",
    "#HTML(ani1.to_jshtml())\n",
    "#ani.save('testing.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function cvtColor:\n",
      "\n",
      "cvtColor(...)\n",
      "    cvtColor(src, code[, dst[, dstCn]]) -> dst\n",
      "    .   @brief Converts an image from one color space to another.\n",
      "    .   \n",
      "    .   The function converts an input image from one color space to another. In case of a transformation\n",
      "    .   to-from RGB color space, the order of the channels should be specified explicitly (RGB or BGR). Note\n",
      "    .   that the default color format in OpenCV is often referred to as RGB but it is actually BGR (the\n",
      "    .   bytes are reversed). So the first byte in a standard (24-bit) color image will be an 8-bit Blue\n",
      "    .   component, the second byte will be Green, and the third byte will be Red. The fourth, fifth, and\n",
      "    .   sixth bytes would then be the second pixel (Blue, then Green, then Red), and so on.\n",
      "    .   \n",
      "    .   The conventional ranges for R, G, and B channel values are:\n",
      "    .   -   0 to 255 for CV_8U images\n",
      "    .   -   0 to 65535 for CV_16U images\n",
      "    .   -   0 to 1 for CV_32F images\n",
      "    .   \n",
      "    .   In case of linear transformations, the range does not matter. But in case of a non-linear\n",
      "    .   transformation, an input RGB image should be normalized to the proper value range to get the correct\n",
      "    .   results, for example, for RGB \\f$\\rightarrow\\f$ L\\*u\\*v\\* transformation. For example, if you have a\n",
      "    .   32-bit floating-point image directly converted from an 8-bit image without any scaling, then it will\n",
      "    .   have the 0..255 value range instead of 0..1 assumed by the function. So, before calling #cvtColor ,\n",
      "    .   you need first to scale the image down:\n",
      "    .   @code\n",
      "    .   img *= 1./255;\n",
      "    .   cvtColor(img, img, COLOR_BGR2Luv);\n",
      "    .   @endcode\n",
      "    .   If you use #cvtColor with 8-bit images, the conversion will have some information lost. For many\n",
      "    .   applications, this will not be noticeable but it is recommended to use 32-bit images in applications\n",
      "    .   that need the full range of colors or that convert an image before an operation and then convert\n",
      "    .   back.\n",
      "    .   \n",
      "    .   If conversion adds the alpha channel, its value will set to the maximum of corresponding channel\n",
      "    .   range: 255 for CV_8U, 65535 for CV_16U, 1 for CV_32F.\n",
      "    .   \n",
      "    .   @param src input image: 8-bit unsigned, 16-bit unsigned ( CV_16UC... ), or single-precision\n",
      "    .   floating-point.\n",
      "    .   @param dst output image of the same size and depth as src.\n",
      "    .   @param code color space conversion code (see #ColorConversionCodes).\n",
      "    .   @param dstCn number of channels in the destination image; if the parameter is 0, the number of the\n",
      "    .   channels is derived automatically from src and code.\n",
      "    .   \n",
      "    .   @see @ref imgproc_color_conversions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.cvtColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-5fce719013aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUMat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCV_8UC3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mhsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# more of processing before fetching the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mhsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_HSV2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from UMatFileVideoStream import UMatFileVideoStream\n",
    "\n",
    "video = UMatFileVideoStream('E:\\FFOutput\\C100~2.mov').start()\n",
    "rgb = cv2.UMat(video.height, video.width, cv2.CV_8UC3)\n",
    "while not video.stopped:\n",
    "    hsv = cv2.cvtColor(video.read(), cv2.COLOR_BGR2RGB)\n",
    "    # more of processing before fetching the images\n",
    "    hsv = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    img = hsv.get()   # image is now a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([85774, 85775, 85776, 85777, 85778, 85779, 85780, 85781, 85782,\n",
       "            85783,\n",
       "            ...\n",
       "             4818,  4819,  4820,  4821,  4822,  4823,  4824,  4825,  4826,\n",
       "             4827],\n",
       "           dtype='int64', name='Timestamp', length=5454)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(HRdata.index-xmin).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax2)=plt.subplots(1,1,figsize=(12,12))\n",
    "im2=ax2.imshow(inF[0])\n",
    "plt.show()\n",
    "def update_image(j):\n",
    "    #print(j)\n",
    "    global x1,x2\n",
    "    #if j<(slider3.value*fps):\n",
    "        #print(\"Updaing \",j)\n",
    "    im2=ax2.imshow(inF[(j)])\n",
    "\n",
    "ani1 = FuncAnimation(fig, update_image, frames=(5*20), interval=1000/20,repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r'E:\\Stress on the road\\Pilots\\testforpablo.mov')  \n",
    "\n",
    "def grab_frame(cap):\n",
    "    ret,frame = cap.read()\n",
    "    return cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def update_image(j):\n",
    "    im2.set_data(grab_frame(cap))\n",
    "    \n",
    "  \n",
    "fig1,(ax2)=plt.subplots(1,1,figsize=(12,12))\n",
    "im2 = ax2.imshow(grab_frame(cap))\n",
    "plt.show()\n",
    "ani1 = FuncAnimation(plt.gcf(), update_image, frames=5*20, interval=300/20,repeat=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
